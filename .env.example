# =============================================================================
# Frontend Configuration
# =============================================================================

# Worker API URL for data and assessment
# - For local development: Run worker locally with `npm run worker:dev`
# - For production: https://qalam-api.foyzul.workers.dev
NEXT_PUBLIC_API_URL="https://qalam-api.foyzul.workers.dev"

# =============================================================================
# LLM Configuration for Verse Analysis Seeding (scripts/seed-analysis.ts)
# =============================================================================

# Backend selection: 'ollama' or 'lms' (default: ollama)
LLM_BACKEND="ollama"

# Ollama (Local LLM)
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="qwen3:4b"

# LM Studio (OpenAI-compatible API)
LMS_BASE_URL="http://localhost:1234"
LMS_MODEL="local-model"

# =============================================================================
# Worker LLM Configuration (set via wrangler secret for production)
# =============================================================================
# Note: These are configured in the Worker via wrangler.toml and secrets.
# See worker/wrangler.toml for configuration details.
#
# For local Worker development, you can set these in a .dev.vars file in the worker/ directory:
# TOGETHER_API_KEY=your-together-api-key-here
